{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPT-4 turbo for policy area classification\n",
    "\n",
    "In this notebook, we take data collected by Benoit et al. ([2016]()) to illustrate how to use GPT-4-turbo through the OpenAI chat completions API to classify texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4-turbo-preview'\n",
    "# note: if you do not have an OpenAI Plus subscription, use gpt-3.5-turbo instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "# define a class to count tokens\n",
    "class TokenCounter:\n",
    "    def __init__(self, encoding_name: Union[str, None] = None, model: Union[str, None] = None):\n",
    "        \"\"\"\n",
    "        Initialize the tokenizer with either a model or an encoding name.\n",
    "\n",
    "        Args:\n",
    "            encoding_name (Union[str, None]): The name of the encoding to use. Default is None.\n",
    "            model (Union[str, None]): The model to use for encoding. Default is None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If neither model nor encoding_name is provided.\n",
    "            ValueError: If both model and encoding_name are provided.\n",
    "        \"\"\"\n",
    "        # ensure that either model or encoding_name is provided\n",
    "        if model is None and encoding_name is None:\n",
    "            raise ValueError(\"Either `model` or `encoding_name` must be provided.\")\n",
    "        if model is not None and encoding_name is not None:\n",
    "            raise ValueError(\"Only one of `model` or `encoding_name` can be provided.\")\n",
    "        if encoding_name:\n",
    "            self.encoding = tiktoken.get_encoding(encoding_name)\n",
    "        else:\n",
    "            self.encoding = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    def count_tokens(self, input: Union[str, List[str]]) -> Union[int, List[int]]:\n",
    "        \"\"\"\n",
    "        Count the number of tokens in the input.\n",
    "\n",
    "        Args:\n",
    "            input (Union[str, List[str]]): The input to tokenize. Can be a string or a list of strings.\n",
    "\n",
    "        Returns:\n",
    "            Union[int, List[int]]: The number of tokens in the input. If the input is a list, returns a list of token counts.\n",
    "        \"\"\"\n",
    "        if isinstance(input, str):\n",
    "            return len(self.encoding.encode(input))\n",
    "        else:\n",
    "            toks = self.encoding.encode_batch(input)\n",
    "            return [len(t) for t in toks]\n",
    "\n",
    "    def __call__(self, input: Union[str, List[str]]) -> Union[int, List[int]]:\n",
    "        \"\"\"\n",
    "        Call the tokenizer on the input. This is equivalent to calling count_tokens.\n",
    "\n",
    "        Args:\n",
    "            input (Union[str, List[str]]): The input to tokenize. Can be a string or a list of strings.\n",
    "\n",
    "        Returns:\n",
    "            Union[int, List[int]]: The number of tokens in the input. If the input is a list, returns a list of token counts.\n",
    "        \"\"\"\n",
    "        return self.count_tokens(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the TokenCounter\n",
    "token_counter = TokenCounter(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt instructions from Benoit et al.'s original crowd coding instructions (see data/benoit_crowdsourced_2016/instructions/) \n",
    "instructions = \"\"\"\n",
    "Your task is to read sentences from political texts and judging whether they deal with economic or social policy.\n",
    "\n",
    "The sentences you will be asked to interpret come from political party manifestos. Some of these sentences will deal with economic policy; some will deal with social policy; other sentences will deal with neither economic nor social policy. We tell you below about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "First, you will read a short section from a party manifesto. For the focal sentence enclosed in triple quotes, indicate your best judgment about whether it mainly refers to economic policy, to social policy, or to neither.\n",
    "\n",
    "For each focal sentence, choose one of the following categories: \"economic\", \"social\", or \"neither\". If the sentence refers to economic policy, select \"economic\"; if it refers to social policy, select \"social\". If the sentence does not refer to either policy area, select \"neither\".\n",
    "\n",
    "## What is \"economic\" policy?\n",
    "\n",
    "**\"Economic\" policies** deal with all aspects of the economy, including:\n",
    "\n",
    "- Taxation\n",
    "- Government spending\n",
    "- Services provided by the government or other public bodies\n",
    "- Pensions, unemployment and welfare benefits, and other state benefits\n",
    "- Property, investment and share ownership, public or private\n",
    "- Interest rates and exchange rates\n",
    "- Regulation of economic activity, public or private\n",
    "- Relations between employers, workers and trade unions\n",
    "\n",
    "## What is \"social\" policy?\n",
    "\n",
    "**\"Social\" policies** deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity, including:\n",
    "\n",
    "- Policing, crime, punishment and rehabilitation of offenders;\n",
    "- Immigration, relations between social groups, discrimination and multiculturalism;\n",
    "- The role of the state in regulating the social and moral behavior of individuals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = \"../../data/benoit_crowdsourced_2016/benoit_crowdsourced_2016_policy_area.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "# keep only gold-standard examples\n",
    "df = df[df.metadata__gold]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'text', 'label', 'metadata__gold', 'metadata__sentence_id',\n",
       "       'metadata__pre_sentence', 'metadata__post_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When distributing sentences to crowd workers for coding, Benoit et al. provided the sentence(s) preceeding and following the to-be-coded sentence.\n",
    "We will replicate this approach and thus need to add the context sentences to the to-be-coded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct input \n",
    "def construct_input(row):\n",
    "    out = \"\"\n",
    "    if isinstance(row['metadata__pre_sentence'], str):\n",
    "        out += row['metadata__pre_sentence'].strip() + \" \"\n",
    "    # wrap the to-be-coded sentence in triple quotes (as noted in the instructions)\n",
    "    out += '\"\"\"'\n",
    "    out += row['text'].strip()\n",
    "    out += '\"\"\"'\n",
    "    if isinstance(row['metadata__post_sentence'], str):\n",
    "        out += \" \" + row['metadata__post_sentence'].strip()\n",
    "    return out\n",
    "\n",
    "df['input'] = df.apply(construct_input, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'A vast change separates the Britain of today from the Britain of the late 1970s. Is it really only such a short time ago that inflation rose to an annual rate of 27 per cent? \"\"\"That the leader of the Transport and General Workers\\' Union was widely seen as the most powerful man in the land?\"\"\" That a minority Labour Government, staggering from crisis to crisis on borrowed money, was nonetheless maintained in power by the Liberal Party in return for the paper concession of a Lib-Lab pact? And that Labour\\'s much-vaunted pay pact with the unions collapsed in the industrial anarchy of the winter of discontent, n which the dead went unburied, rubbish piled up in the streets and the country was gripped by a creeping paralysis which Labour was powerless to cure?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "df.label.values[i], df['input'].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": df['input'].values[4]}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    seed=42,\n",
    "    temperature=0.0,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "results = response.choices[0].message.content\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify multiple texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    messages = [ \n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        temperature=0.0,\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    results = response.choices[0].message.content\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000621</td>\n",
       "      <td>By such steadfastness, we have not only rebuil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10008851</td>\n",
       "      <td>set up safe facilities for disposing of radioa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001231</td>\n",
       "      <td>In 1832 Britain took the first step with the G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010111</td>\n",
       "      <td>Conclusion: The Way Forward. The proposals out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000991</td>\n",
       "      <td>A fair electoral system will have that effect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10007441</td>\n",
       "      <td>but much has been done. The great majority of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>40007181</td>\n",
       "      <td>Our national DNA database - the first in the w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>40007211</td>\n",
       "      <td>Since 1985 the average sentence for violence a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>40007951</td>\n",
       "      <td>Anyone convicted of a second serious sexual or...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10007201</td>\n",
       "      <td>and in the wider world where violence is glamo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                                              input  label\n",
       "0   10000621  By such steadfastness, we have not only rebuil...      1\n",
       "1   10008851  set up safe facilities for disposing of radioa...      1\n",
       "2   20001231  In 1832 Britain took the first step with the G...      1\n",
       "3   10010111  Conclusion: The Way Forward. The proposals out...      1\n",
       "4   20000991  A fair electoral system will have that effect ...      1\n",
       "..       ...                                                ...    ...\n",
       "70  10007441  but much has been done. The great majority of ...      3\n",
       "71  40007181  Our national DNA database - the first in the w...      3\n",
       "72  40007211  Since 1985 the average sentence for violence a...      3\n",
       "73  40007951  Anyone convicted of a second serious sexual or...      3\n",
       "74  10007201  and in the wider world where violence is glamo...      3\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a sample of 25 texts from each label class\n",
    "samples = df.groupby('label').sample(25, random_state=42)[[\"uid\", \"input\", \"label\"]].reset_index(drop=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute how much it will cost to request classifications for this sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35448"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens in inputs\n",
    "n_tokens = samples.input.apply(token_counter.count_tokens).sum()\n",
    "# add token count for instructions\n",
    "n_tokens += token_counter(instructions) * len(samples)\n",
    "# add token count for outputs (multiplied by cost factor for output vs. input)\n",
    "n_tokens += len(samples) * 3\n",
    "\n",
    "# comopute cost (see https://openai.com/pricing)\n",
    "n_tokens/1000*0.01 # dollar cents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** had we used all 506 texts, we'd pay approx. U.S. $ 3.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify: apply custom classification function to all inputs\n",
    "results = samples.input.apply(classify_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Since the dataset records texts \"true\" labels (based on the authors expert judgments), we can compute standard [multi-class classification metrics](https://www.kaggle.com/code/nkitgupta/evaluation-metrics-for-multi-class-classification) by comparing true labels to GPT's classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       0.96      0.92      0.94        25\n",
      "     neither       0.92      0.92      0.92        25\n",
      "      social       0.92      0.96      0.94        25\n",
      "\n",
      "    accuracy                           0.93        75\n",
      "   macro avg       0.93      0.93      0.93        75\n",
      "weighted avg       0.93      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate: compute performance metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "id2label = {2: \"economic\", 1: \"neither\", 3: \"social\"}\n",
    "print(classification_report(samples.label.map(id2label), results.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_text_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
