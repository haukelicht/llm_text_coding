{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPT-4 turbo for policy area classification\n",
    "\n",
    "In this notebook, we take data collected by Benoit et al. ([2016](doi.org/10.1017/S0003055416000058)) to illustrate how to use GPT-4-turbo through the OpenAI chat completions API to classify texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# for using OpenAI API\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# for data wrangling\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4-0125-preview'\n",
    "# note: if you do not have an OpenAI Plus subscription, use gpt-3.5-turbo instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "# define a class to count tokens\n",
    "class TokenCounter:\n",
    "    def __init__(self, encoding_name: Union[str, None] = None, model: Union[str, None] = None):\n",
    "        \"\"\"\n",
    "        Initialize the tokenizer with either a model or an encoding name.\n",
    "\n",
    "        Args:\n",
    "            encoding_name (Union[str, None]): The name of the encoding to use. Default is None.\n",
    "            model (Union[str, None]): The model to use for encoding. Default is None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If neither model nor encoding_name is provided.\n",
    "            ValueError: If both model and encoding_name are provided.\n",
    "        \"\"\"\n",
    "        # ensure that either model or encoding_name is provided\n",
    "        if model is None and encoding_name is None:\n",
    "            raise ValueError(\"Either `model` or `encoding_name` must be provided.\")\n",
    "        if model is not None and encoding_name is not None:\n",
    "            raise ValueError(\"Only one of `model` or `encoding_name` can be provided.\")\n",
    "        if encoding_name:\n",
    "            self.encoding = tiktoken.get_encoding(encoding_name)\n",
    "        else:\n",
    "            self.encoding = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    def count_tokens(self, input: Union[str, List[str]]) -> Union[int, List[int]]:\n",
    "        \"\"\"\n",
    "        Count the number of tokens in the input.\n",
    "\n",
    "        Args:\n",
    "            input (Union[str, List[str]]): The input to tokenize. Can be a string or a list of strings.\n",
    "\n",
    "        Returns:\n",
    "            Union[int, List[int]]: The number of tokens in the input. If the input is a list, returns a list of token counts.\n",
    "        \"\"\"\n",
    "        if isinstance(input, str):\n",
    "            return len(self.encoding.encode(input))\n",
    "        else:\n",
    "            toks = self.encoding.encode_batch(input)\n",
    "            return [len(t) for t in toks]\n",
    "\n",
    "    def __call__(self, input: Union[str, List[str]]) -> Union[int, List[int]]:\n",
    "        \"\"\"\n",
    "        Call the tokenizer on the input. This is equivalent to calling count_tokens.\n",
    "\n",
    "        Args:\n",
    "            input (Union[str, List[str]]): The input to tokenize. Can be a string or a list of strings.\n",
    "\n",
    "        Returns:\n",
    "            Union[int, List[int]]: The number of tokens in the input. If the input is a list, returns a list of token counts.\n",
    "        \"\"\"\n",
    "        return self.count_tokens(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the TokenCounter\n",
    "token_counter = TokenCounter(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = os.path.join('..', '..')\n",
    "data_path = os.path.join(base_path, 'data', 'benoit_crowdsourced_2016') \n",
    "\n",
    "fp = os.path.join(data_path, \"benoit_crowdsourced_2016_policy_area.csv\")\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "# keep only gold-standard examples\n",
    "df = df[df.metadata__gold]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>metadata__gold</th>\n",
       "      <th>metadata__sentence_id</th>\n",
       "      <th>metadata__pre_sentence</th>\n",
       "      <th>metadata__post_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000031</td>\n",
       "      <td>We have risen to fresh challenges at home and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10000031</td>\n",
       "      <td>We have discovered a new strength and a new pr...</td>\n",
       "      <td>Once again our economy is strong. Our industri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid                                               text  label  \\\n",
       "2  10000031  We have risen to fresh challenges at home and ...      1   \n",
       "\n",
       "   metadata__gold  metadata__sentence_id  \\\n",
       "2            True               10000031   \n",
       "\n",
       "                              metadata__pre_sentence  \\\n",
       "2  We have discovered a new strength and a new pr...   \n",
       "\n",
       "                             metadata__post_sentence  \n",
       "2  Once again our economy is strong. Our industri...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    225\n",
       "1    181\n",
       "3    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {1: \"neither\", 2: \"economic\", 3: \"social\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When distributing sentences to crowd workers for coding, Benoit et al. provided the sentence(s) preceeding and following the to-be-coded sentence.\n",
    "We will replicate this approach and thus need to add the context sentences to the to-be-coded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct input \n",
    "def construct_input(row):\n",
    "    out = \"\"\n",
    "    if isinstance(row['metadata__pre_sentence'], str):\n",
    "        out += row['metadata__pre_sentence'].strip() + \" \"\n",
    "    # wrap the to-be-coded sentence in triple quotes (as noted in the instructions)\n",
    "    out += '\"\"\"'\n",
    "    out += row['text'].strip()\n",
    "    out += '\"\"\"'\n",
    "    if isinstance(row['metadata__post_sentence'], str):\n",
    "        out += \" \" + row['metadata__post_sentence'].strip()\n",
    "    return out\n",
    "\n",
    "df['input'] = df.apply(construct_input, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       We have discovered a new strength and a new pr...\n",
       "12      Given the opportunities provided by Conservati...\n",
       "13      Together we are building One Nation of free, p...\n",
       "14      A Conservative dream is at last becoming a rea...\n",
       "17      A vast change separates the Britain of today f...\n",
       "                              ...                        \n",
       "4769    We will bring the government's policy of forci...\n",
       "4884    Parliament will remain free to enhance these r...\n",
       "4968    The country takes pride in their professionali...\n",
       "4984    We believe that part of its expertise can be e...\n",
       "5015    A new Labour government will use those assets ...\n",
       "Name: input, Length: 506, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt instructions from Benoit et al.'s original crowd coding instructions (see data/benoit_crowdsourced_2016/instructions/) \n",
    "instructions = \"\"\"\n",
    "Your task is to read sentences from political texts and judging whether they deal with economic or social policy.\n",
    "\n",
    "The sentences you will be asked to interpret come from political party manifestos. Some of these sentences will deal with economic policy; some will deal with social policy; other sentences will deal with neither economic nor social policy. We tell you below about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "First, you will read a short section from a party manifesto. For the focal sentence enclosed in triple quotes, indicate your best judgment about whether it mainly refers to economic policy, to social policy, or to neither.\n",
    "\n",
    "For each focal sentence, choose one of the following categories: \"economic\", \"social\", or \"neither\". If the sentence refers to economic policy, select \"economic\"; if it refers to social policy, select \"social\". If the sentence does not refer to either policy area, select \"neither\".\n",
    "\n",
    "## What is \"economic\" policy?\n",
    "\n",
    "**\"Economic\" policies** deal with all aspects of the economy, including:\n",
    "\n",
    "- Taxation\n",
    "- Government spending\n",
    "- Services provided by the government or other public bodies\n",
    "- Pensions, unemployment and welfare benefits, and other state benefits\n",
    "- Property, investment and share ownership, public or private\n",
    "- Interest rates and exchange rates\n",
    "- Regulation of economic activity, public or private\n",
    "- Relations between employers, workers and trade unions\n",
    "\n",
    "## What is \"social\" policy?\n",
    "\n",
    "**\"Social\" policies** deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity, including:\n",
    "\n",
    "- Policing, crime, punishment and rehabilitation of offenders;\n",
    "- Immigration, relations between social groups, discrimination and multiculturalism;\n",
    "- The role of the state in regulating the social and moral behavior of individuals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: A vast change separates the Britain of today from the Britain of the late 1970s. Is it really only such a short time ago that inflation rose to an annual rate of 27 per cent? \"\"\"That the leader of the Transport and General Workers' Union was widely seen as the most powerful man in the land?\"\"\" That a minority Labour Government, staggering from crisis to crisis on borrowed money, was nonetheless maintained in power by the Liberal Party in return for the paper concession of a Lib-Lab pact? And that Labour's much-vaunted pay pact with the unions collapsed in the industrial anarchy of the winter of discontent, n which the dead went unburied, rubbish piled up in the streets and the country was gripped by a creeping paralysis which Labour was powerless to cure?\n",
      "LABEL: economic\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "print('TEXT:', df.input.values[i])\n",
    "print('LABEL:', id2label[df.label.values[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": df['input'].values[i]}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    seed=42,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "results = response.choices[0].message.content\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    messages = [ \n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    results = response.choices[0].message.content\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000621</td>\n",
       "      <td>By such steadfastness, we have not only rebuil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10008851</td>\n",
       "      <td>set up safe facilities for disposing of radioa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001231</td>\n",
       "      <td>In 1832 Britain took the first step with the G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010111</td>\n",
       "      <td>Conclusion: The Way Forward. The proposals out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000991</td>\n",
       "      <td>A fair electoral system will have that effect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10007441</td>\n",
       "      <td>but much has been done. The great majority of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>40007181</td>\n",
       "      <td>Our national DNA database - the first in the w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>40007211</td>\n",
       "      <td>Since 1985 the average sentence for violence a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>40007951</td>\n",
       "      <td>Anyone convicted of a second serious sexual or...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10007201</td>\n",
       "      <td>and in the wider world where violence is glamo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                                              input  label\n",
       "0   10000621  By such steadfastness, we have not only rebuil...      1\n",
       "1   10008851  set up safe facilities for disposing of radioa...      1\n",
       "2   20001231  In 1832 Britain took the first step with the G...      1\n",
       "3   10010111  Conclusion: The Way Forward. The proposals out...      1\n",
       "4   20000991  A fair electoral system will have that effect ...      1\n",
       "..       ...                                                ...    ...\n",
       "70  10007441  but much has been done. The great majority of ...      3\n",
       "71  40007181  Our national DNA database - the first in the w...      3\n",
       "72  40007211  Since 1985 the average sentence for violence a...      3\n",
       "73  40007951  Anyone convicted of a second serious sexual or...      3\n",
       "74  10007201  and in the wider world where violence is glamo...      3\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a sample of 25 texts from each label class\n",
    "samples = df.groupby('label').sample(25, random_state=42)[[\"uid\", \"input\", \"label\"]].reset_index(drop=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute how much it will cost to request classifications for this sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# input tokens: 35223\n"
     ]
    }
   ],
   "source": [
    "# number of tokens in inputs\n",
    "n_input_tokens = samples.input.apply(token_counter.count_tokens).sum()\n",
    "# add token count for instructions (for each example)\n",
    "n_input_tokens += token_counter(instructions) * len(samples)\n",
    "print('# input tokens:', n_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# output tokens: 75\n"
     ]
    }
   ],
   "source": [
    "# given that we instruct the model to reply only with the category, the number of output tokens per example is 1\n",
    "n_output_tokens = len(samples)\n",
    "print('# output tokens:', n_output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go to https://openai.com/pricing to see what's the actual pricing for using the GPT-4-turbo model.\n",
    "\n",
    "On March 24, 2024, the princing is \n",
    "\n",
    "- $10.00 per one million (1M) **input** tokens and\n",
    "- $30.00/1M **output** tokens (hence the cost-factor above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.52455"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comopute cost (see https://openai.com/pricing)\n",
    "n_input_tokens/1_000_00*10 + n_output_tokens/1_000_000*30 # dollar cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e3d30f8d50467ea272d74998a121b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classify: apply custom classification function to all inputs\n",
    "results = samples.input.progress_apply(classify_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input\n",
       "social      28\n",
       "economic    24\n",
       "neither     23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Since the dataset records texts \"true\" labels (based on the authors expert judgments), we can compute standard [multi-class classification metrics](https://www.kaggle.com/code/nkitgupta/evaluation-metrics-for-multi-class-classification) by comparing true labels to GPT's classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       0.96      0.92      0.94        25\n",
      "     neither       1.00      0.92      0.96        25\n",
      "      social       0.89      1.00      0.94        25\n",
      "\n",
      "    accuracy                           0.95        75\n",
      "   macro avg       0.95      0.95      0.95        75\n",
      "weighted avg       0.95      0.95      0.95        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(samples.label.map(id2label), results.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get two examples (at random) per category that are not in our sample of to-be-classified examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000541</td>\n",
       "      <td>Government must enable society to take the lon...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000031</td>\n",
       "      <td>We know that it is possible to unite our count...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30003571</td>\n",
       "      <td>Our policies for employment, education, housin...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20004691</td>\n",
       "      <td>The &amp;lt;U+00A3&amp;gt;10 Christmas bonus has becam...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40007901</td>\n",
       "      <td>Persistent offenders account for a high propor...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004751</td>\n",
       "      <td>FAMILIES IN WORK. We will add £5 per week to t...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid                                              input     label\n",
       "0  20000541  Government must enable society to take the lon...   neither\n",
       "1  20000031  We know that it is possible to unite our count...   neither\n",
       "5  30003571  Our policies for employment, education, housin...    social\n",
       "2  20004691  The &lt;U+00A3&gt;10 Christmas bonus has becam...  economic\n",
       "4  40007901  Persistent offenders account for a high propor...    social\n",
       "3  20004751  FAMILIES IN WORK. We will add £5 per week to t...  economic"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = df[~df.uid.isin(samples.uid)].groupby('label').sample(2, random_state=42)[[\"uid\", \"input\", \"label\"]].reset_index(drop=True)\n",
    "# resuffle\n",
    "examples = examples.sample(frac=1.0, random_state=42)\n",
    "# convert numberic to string labels\n",
    "examples['label'] = examples['label'].map(id2label)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, examples: pd.DataFrame):\n",
    "    messages = [{\"role\": \"system\", \"content\": instructions}]\n",
    "    \n",
    "    for _, d in examples.iterrows():\n",
    "        messages +=  [   \n",
    "            {\"role\": \"user\", \"content\": d.input},\n",
    "            {\"role\": \"assistant\", \"content\": d.label}\n",
    "        ]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    results = response.choices[0].message.content\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update our estimate of the number of input tokens and the resulting cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.60445"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input_tokens += examples.input.apply(token_counter.count_tokens).sum() + len(examples)*3\n",
    "\n",
    "# compute cost\n",
    "n_input_tokens/1_000_00*10 + n_output_tokens/1_000_000*30 # dollar cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74096a9869d945c49e03a42d04624ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classify: apply custom classification function to all inputs\n",
    "results = samples.input.progress_apply(classify_text, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input\n",
       "neither     28\n",
       "social      25\n",
       "economic    22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       1.00      0.88      0.94        25\n",
      "     neither       0.86      0.96      0.91        25\n",
      "      social       0.96      0.96      0.96        25\n",
      "\n",
      "    accuracy                           0.93        75\n",
      "   macro avg       0.94      0.93      0.93        75\n",
      "weighted avg       0.94      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(samples.label.map(id2label), results.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there is no improvement of the few- compared to the zero-shot classification performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_text_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
